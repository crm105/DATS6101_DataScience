#Read in data file. Note, second sheet contains data
df <- read_xlsx("ferc_exercise.xlsx", sheet = 2)
#Some quick descriptives
length(unique(df$Customer))
summary(df$Timeline)
# Generate escriptive statistics for products
df.products <- df %>%
group_by(Product) %>%
summarize(total.sales = sum(Amount), avg.sale.value = mean(Amount),
total.transactions = n())
#Number of Unique products in dataset and total transactions
length(df.products$Product)
sum(df.products$total.transactions)
#Plot of total transactions by product.
#Too many X axis values to visually determine which products. But
#good for finding outliers. No significant outliers at first glance.
ggplot(df.products, aes(x = Product, y = total.transactions)) +
geom_bar(stat = "identity") + theme_bw() +
labs(title = "Total Transactions by Product",
caption = "Source: FERC Exercise" ) +  ylab ( "Transactions")+
theme(title = element_text(size = 13, face = "bold"))+
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
hist(df.products$total.transactions)
#Plot for average transaction value. Clearly one huge outlier
#We can investigate further.
ggplot(df.products, aes(x = Product, y = avg.sale.value)) +
geom_bar(stat = "identity") + theme_bw()+
labs(title = "Average Sale Value by Product", subtitle = "04/2013 - 04/2014 (US Dollars)",
caption = "Source: FERC Exercise" ) +  ylab ( "Sales")+
theme(title = element_text(size = 13, face = "bold"),
plot.subtitle = element_text (size = 10)) +
annotate("text", x = c(18), y = c(4550),
label = df.products[which.max(df.products$avg.sale.value),]$Product,
color="orange", size=4 , angle=50, fontface="bold")+
annotate("segment", x = 17, xend = 13, y = 4800, yend = 5000,
colour = "orange", size=1, alpha=1, arrow=arrow())+
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
top_n(df.products, 10, avg.sale.value)
#Determine which product has outlier average sale value.
#Cote de Blaye had max average sale value, with 9 transactions
# 5466$ per sale
df.products[which.max(df.products$avg.sale.value),]$Product
top.products <- top_n(df.products, 10, avg.sale.value)
#Calculate how many standard deviations away Average sale of Cote De Blaye was from
#mean of average product sales
(df.products[which.max(df.products$avg.sale.value),]$avg.sale.value - mean(df.products$avg.sale.value))/
sd(df.products$avg.sale.value)
#Return to original dataset to see who is buying Cote de Blaye
cote <- df[df$Product == "Côte de Blaye",]
cote
#Visual Inspection of Cote de Blaye purchases suggest high variance in
#sale prices. Standard deviation is 2901, more than half the mean value
sd(cote$Amount)
sd(cote$Amount)/ mean(cote$Amount)
#Let's take a brief look at Simob's purcases compared to the entire set
SIMOB <- df[df$Customer == "SIMOB",]
SIMOB
sum(SIMOB$Amount); mean(SIMOB$Amount)
#Create a dataframe of transactions grouped by customers
df.customers <- df %>%
group_by(Customer) %>%
summarize(total.purchases = sum(Amount), avg.purchase.value = mean(Amount),
total.transactions = n())
#Show the top 10 customers by average transaction value.
top.customers <- top_n(df.customers, 10, avg.purchase.value)
#Brief descriptives on customer purchases
mean(df.customers$total.purchases); sd(df.customers$total.purchases)
hist(df.customers$total.purchases, main= "Histogram of Customer's Total Expenditure",
xlab = "Total Expenditure")
length(unique(df$Product))
#Title: Data Analysis for FERC Interview
#Author: Christopher Montgomery
#Last Revised: 1//10/2019
#Input: ferc_exercise.xlsx
#Output: ferc_write_up.docx
# Set correct directory to locate data and save script.
#This line is directory specific
#setwd("Documents/active_projects/FERC_assignment")
#Import libraries required for analysis
library(readxl); library(ggplot2); library(tidyverse)
#Read in data file. Note, second sheet contains data
df <- read_xlsx("ferc_exercise.xlsx", sheet = 2)
#Some quick descriptives
length(unique(df$Customer))
summary(df$Timeline)
# Generate escriptive statistics for products
df.products <- df %>%
group_by(Product) %>%
summarize(total.sales = sum(Amount), avg.sale.value = mean(Amount),
total.transactions = n())
#Number of Unique products in dataset and total transactions
length(df.products$Product)
sum(df.products$total.transactions)
#Plot of total transactions by product.
#Too many X axis values to visually determine which products. But
#good for finding outliers. No significant outliers at first glance.
ggplot(df.products, aes(x = Product, y = total.transactions)) +
geom_bar(stat = "identity") + theme_bw() +
labs(title = "Total Transactions by Product",
caption = "Source: FERC Exercise" ) +  ylab ( "Transactions")+
theme(title = element_text(size = 13, face = "bold"))+
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
hist(df.products$total.transactions)
#Plot for average transaction value. Clearly one huge outlier
#We can investigate further.
ggplot(df.products, aes(x = Product, y = avg.sale.value)) +
geom_bar(stat = "identity") + theme_bw()+
labs(title = "Average Sale Value by Product", subtitle = "04/2013 - 04/2014 (US Dollars)",
caption = "Source: FERC Exercise" ) +  ylab ( "Sales")+
theme(title = element_text(size = 13, face = "bold"),
plot.subtitle = element_text (size = 10)) +
annotate("text", x = c(18), y = c(4550),
label = df.products[which.max(df.products$avg.sale.value),]$Product,
color="orange", size=4 , angle=50, fontface="bold")+
annotate("segment", x = 17, xend = 13, y = 4800, yend = 5000,
colour = "orange", size=1, alpha=1, arrow=arrow())+
theme(
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
top_n(df.products, 10, avg.sale.value)
#Determine which product has outlier average sale value.
#Cote de Blaye had max average sale value, with 9 transactions
# 5466$ per sale
df.products[which.max(df.products$avg.sale.value),]$Product
top.products <- top_n(df.products, 10, avg.sale.value)
#Calculate how many standard deviations away Average sale of Cote De Blaye was from
#mean of average product sales
(df.products[which.max(df.products$avg.sale.value),]$avg.sale.value - mean(df.products$avg.sale.value))/
sd(df.products$avg.sale.value)
#Return to original dataset to see who is buying Cote de Blaye
cote <- df[df$Product == "Côte de Blaye",]
cote
#Visual Inspection of Cote de Blaye purchases suggest high variance in
#sale prices. Standard deviation is 2901, more than half the mean value
sd(cote$Amount)
sd(cote$Amount)/ mean(cote$Amount)
#Let's take a brief look at Simob's purcases compared to the entire set
SIMOB <- df[df$Customer == "SIMOB",]
SIMOB
sum(SIMOB$Amount); mean(SIMOB$Amount)
#Create a dataframe of transactions grouped by customers
df.customers <- df %>%
group_by(Customer) %>%
summarize(total.purchases = sum(Amount), avg.purchase.value = mean(Amount),
total.transactions = n())
#Show the top 10 customers by average transaction value.
top.customers <- top_n(df.customers, 10, avg.purchase.value)
#Brief descriptives on customer purchases
mean(df.customers$total.purchases); sd(df.customers$total.purchases)
hist(df.customers$total.purchases, main= "Histogram of Customer's Total Expenditure",
xlab = "Total Expenditure")
length(unique(df$Product))
#setwd("Documents/active_projects/FERC_assignment")
setwd(getSrcDirectory()[1])
source("analysis.r", chdir = TRUE)
getwd()
setwd("../../..")
getwd()
source("analysis.r", chdir = TRUE)
?source
dir <- dirname(parent.frame(2)$ofile)
?mpg
??mpg
getwd()
setwd("Documents/active_projects/DATS6101_DataScience/eda_project")
#Title: missing_values_analysis.R
#Author: Chris Montgomery
#Last Revised: 2/24/2019
#working_directory: ~DATS6101_DataScience/eda_project
#Input: data/dc_residential_data/DC_properties.csv
#Output:
#Description: This script tests differences in housing characteristics between homes with and without price
#values. Characteristics of interest were determined by conversation with group members and can be found in
#EDA_outline.doc
#Import necessary libraries
library(dplyr); library(ggplot2), library(gplots), library(tidyvers)
#Read in the original source data
df.orig <- df <- read.csv("data/dc_residential_data/DC_properties.csv")
#Convert saledate to date, and add sale year column
df$SALEDATE <- as.Date(df$SALEDATE)
df$sale.year <- lubridate::year(df$SALEDATE)
#Create a dataframe that contains clean housing values that will not be dropped
df.clean <- df %>% filter(!is.na(PRICE),  sale.year > 2015)
#Create a dataframe with dropped values for comparison
df.dropped <- df %>% filter(is.na(PRICE),  sale.year > 2015)
#Identify continuous variables of interest for T-tests
cont.variables <- c("BATHRM", "HF_BATHRM", "ROOMS", "BEDRM", "AYB", "YR_RMDL", "EYB", "STORIES", "GBA",
"KITCHENS", "FIREPLACES")
#Identify categorical variables of interest for chi-square tests
cat.variables <- c("HEAT","AC", "GRADE", "EXTWALL", "ROOF", "INTWALL", "QUADRANT")
#Create a loop that conducts a t-test for each of the above variables
t.test.results <-  lapply(seq(1:length(cont.variables)),function(i){
x <- df.clean[,cont.variables[i]]
y <- df.dropped[,cont.variables[i]]
hope[[i]] <-  t.test(x,y, alternative = "two.sided", na.action = na.omit)
})
#Create a loop that reports the significance of each pairwise t-test
for (i in 1:length(cont.variables)){
print(
paste ( "On average, non-missing values have ", signif (100 * t.test.results[[i]]$estimate[[1]] /
t.test.results[[i]]$estimate[[2]], digits = 3 ),"% ", cont.variables[i], " with a t-stat of ",
t.test.results[[i]]$statistic, sep = ""
))
}
#Create a loop that conducts chi-square for each of the categorical variables
df.cat <- df %>% filter( sale.year > 2015)
df.cat$missing <- 0; df.cat[is.na(df.cat$PRICE),"missing"] = 1; df.cat$missing <- as.factor(df.cat$missing)
df.cat <- df.cat %>%  select(cat.variables, missing)
df.cat <-  gather(df.cat, variable, id, 1:7)
df.cat <- df.cat %>% group_by(missing, id) %>% summarize(value = n())
df.cat <-  spread(df.cat, missing, value); colnames(df.cat) <- c( "feature","non-missing", "missing");
df.cat <- df.cat[-(1:2),]
anova.results <-  lapply(seq(1:length(cont.variables)),function(i){
x <- df.clean[,cat.variables[i]]
y <- df.dropped[,cat.variables[i]]
hope[[i]] <-  t.test(x,y, alternative = "two.sided", na.action = na.omit)
})
#Title: missing_values_analysis.R
#Author: Chris Montgomery
#Last Revised: 2/24/2019
#working_directory: ~DATS6101_DataScience/eda_project
#Input: data/dc_residential_data/DC_properties.csv
#Output:
#Description: This script tests differences in housing characteristics between homes with and without price
#values. Characteristics of interest were determined by conversation with group members and can be found in
#EDA_outline.doc
#Import necessary libraries
library(dplyr); library(ggplot2); library(gplots); library(tidyvers)
#Read in the original source data
df.orig <- df <- read.csv("data/dc_residential_data/DC_properties.csv")
#Convert saledate to date, and add sale year column
df$SALEDATE <- as.Date(df$SALEDATE)
df$sale.year <- lubridate::year(df$SALEDATE)
#Create a dataframe that contains clean housing values that will not be dropped
df.clean <- df %>% filter(!is.na(PRICE),  sale.year > 2015)
#Create a dataframe with dropped values for comparison
df.dropped <- df %>% filter(is.na(PRICE),  sale.year > 2015)
#Identify continuous variables of interest for T-tests
cont.variables <- c("BATHRM", "HF_BATHRM", "ROOMS", "BEDRM", "AYB", "YR_RMDL", "EYB", "STORIES", "GBA",
"KITCHENS", "FIREPLACES")
#Identify categorical variables of interest for chi-square tests
cat.variables <- c("HEAT","AC", "GRADE", "EXTWALL", "ROOF", "INTWALL", "QUADRANT")
#Create a loop that conducts a t-test for each of the above variables
t.test.results <-  lapply(seq(1:length(cont.variables)),function(i){
x <- df.clean[,cont.variables[i]]
y <- df.dropped[,cont.variables[i]]
hope[[i]] <-  t.test(x,y, alternative = "two.sided", na.action = na.omit)
})
#Create a loop that reports the significance of each pairwise t-test
for (i in 1:length(cont.variables)){
print(
paste ( "On average, non-missing values have ", signif (100 * t.test.results[[i]]$estimate[[1]] /
t.test.results[[i]]$estimate[[2]], digits = 3 ),"% ", cont.variables[i], " with a t-stat of ",
t.test.results[[i]]$statistic, sep = ""
))
}
#Create a loop that conducts chi-square for each of the categorical variables
df.cat <- df %>% filter( sale.year > 2015)
df.cat$missing <- 0; df.cat[is.na(df.cat$PRICE),"missing"] = 1; df.cat$missing <- as.factor(df.cat$missing)
df.cat <- df.cat %>%  select(cat.variables, missing)
df.cat <-  gather(df.cat, variable, id, 1:7)
df.cat <- df.cat %>% group_by(missing, id) %>% summarize(value = n())
df.cat <-  spread(df.cat, missing, value); colnames(df.cat) <- c( "feature","non-missing", "missing");
df.cat <- df.cat[-(1:2),]
df.cat <- df %>% filter( sale.year > 2015)
df.cat$missing <- 0; df.cat[is.na(df.cat$PRICE),"missing"] = 1; df.cat$missing <- as.factor(df.cat$missing)
df.cat <- df.cat %>%  select(cat.variables, missing)
df.cat <-  gather(df.cat, variable, id, 1:7)
df.cat <- df.cat %>% group_by(missing, id) %>% summarize(value = n())
df.cat <-  spread(df.cat, missing, value); colnames(df.cat) <- c( "feature","non-missing", "missing");
df.cat <- df.cat[-(1:2),]
#Import necessary libraries
library(dplyr); library(ggplot2); library(gplots); library(tidyvers)
#Title: missing_values_analysis.R
#Author: Chris Montgomery
#Last Revised: 2/24/2019
#working_directory: ~DATS6101_DataScience/eda_project
#Input: data/dc_residential_data/DC_properties.csv
#Output:
#Description: This script tests differences in housing characteristics between homes with and without price
#values. Characteristics of interest were determined by conversation with group members and can be found in
#EDA_outline.doc
#Import necessary libraries
library(dplyr); library(ggplot2); library(gplots); library(tidyverse)
#Read in the original source data
df.orig <- df <- read.csv("data/dc_residential_data/DC_properties.csv")
#Convert saledate to date, and add sale year column
df$SALEDATE <- as.Date(df$SALEDATE)
df$sale.year <- lubridate::year(df$SALEDATE)
#Create a dataframe that contains clean housing values that will not be dropped
df.clean <- df %>% filter(!is.na(PRICE),  sale.year > 2015)
#Create a dataframe with dropped values for comparison
df.dropped <- df %>% filter(is.na(PRICE),  sale.year > 2015)
#Identify continuous variables of interest for T-tests
cont.variables <- c("BATHRM", "HF_BATHRM", "ROOMS", "BEDRM", "AYB", "YR_RMDL", "EYB", "STORIES", "GBA",
"KITCHENS", "FIREPLACES")
#Identify categorical variables of interest for chi-square tests
cat.variables <- c("HEAT","AC", "GRADE", "EXTWALL", "ROOF", "INTWALL", "QUADRANT")
#Create a loop that conducts a t-test for each of the above variables
t.test.results <-  lapply(seq(1:length(cont.variables)),function(i){
x <- df.clean[,cont.variables[i]]
y <- df.dropped[,cont.variables[i]]
hope[[i]] <-  t.test(x,y, alternative = "two.sided", na.action = na.omit)
})
#Create a loop that reports the significance of each pairwise t-test
for (i in 1:length(cont.variables)){
print(
paste ( "On average, non-missing values have ", signif (100 * t.test.results[[i]]$estimate[[1]] /
t.test.results[[i]]$estimate[[2]], digits = 3 ),"% ", cont.variables[i], " with a t-stat of ",
t.test.results[[i]]$statistic, sep = ""
))
}
#Create a loop that conducts chi-square for each of the categorical variables
df.cat <- df %>% filter( sale.year > 2015)
df.cat$missing <- 0; df.cat[is.na(df.cat$PRICE),"missing"] = 1; df.cat$missing <- as.factor(df.cat$missing)
df.cat <- df.cat %>%  select(cat.variables, missing)
df.cat <-  gather(df.cat, variable, id, 1:7)
df.cat <- df.cat %>% group_by(missing, id) %>% summarize(value = n())
df.cat <-  spread(df.cat, missing, value); colnames(df.cat) <- c( "feature","non-missing", "missing");
df.cat <- df.cat[-(1:2),]
#Create a loop that reports the significance of each pairwise t-test
for (i in 1:length(cont.variables)){
print(
paste ( "On average, non-missing values have ", signif (100 * t.test.results[[i]]$estimate[[1]] /
t.test.results[[i]]$estimate[[2]], digits = 3 ),"% ", cont.variables[i], " with a t-stat of ",
t.test.results[[i]]$statistic, sep = ""
))
}
t.test.results <-  lapply(seq(1:length(cont.variables)),function(i){
x <- df.clean[,cont.variables[i]]
y <- df.dropped[,cont.variables[i]]
hope[[i]] <-  t.test(x,y, alternative = "two.sided", na.action = na.omit)
})
t.test.results <-  lapply(seq(1:length(cont.variables)),function(i){
x <- df.clean[,cont.variables[i]]
y <- df.dropped[,cont.variables[i]]
t.test.results[[i]] <-  t.test(x,y, alternative = "two.sided", na.action = na.omit)
})
t.test.results <-  lapply(seq(1:length(cont.variables)),function(i){
x <- df.clean[,cont.variables[i]]
y <- df.dropped[,cont.variables[i]]
t.test(x,y, alternative = "two.sided", na.action = na.omit)
})
View(t.test.results)
#Create a loop that reports the significance of each pairwise t-test
for (i in 1:length(cont.variables)){
print(
paste ( "On average, non-missing values have ", signif (100 * t.test.results[[i]]$estimate[[1]] /
t.test.results[[i]]$estimate[[2]], digits = 3 ),"% ", cont.variables[i], " with a t-stat of ",
t.test.results[[i]]$statistic, sep = ""
))
}
t.test.results[1]
#Title: missing_values_analysis.R
#Author: Chris Montgomery
#Last Revised: 2/24/2019
#working_directory: ~DATS6101_DataScience/eda_project
#Input: data/dc_residential_data/DC_properties.csv
#Output:
#Description: This script tests differences in housing characteristics between homes with and without price
#values. Characteristics of interest were determined by conversation with group members and can be found in
#EDA_outline.doc
#Import necessary libraries
library(dplyr); library(ggplot2); library(gplots); library(tidyverse)
#Read in the original source data
df.orig <- df <- read.csv("data/dc_residential_data/DC_properties.csv")
#Convert saledate to date, and add sale year column
df$SALEDATE <- as.Date(df$SALEDATE)
df$sale.year <- lubridate::year(df$SALEDATE)
#Create a dataframe that contains clean housing values that will not be dropped
df.clean <- df %>% filter(!is.na(PRICE),  sale.year > 2015)
#Create a dataframe with dropped values for comparison
df.dropped <- df %>% filter(is.na(PRICE),  sale.year > 2015)
#Identify continuous variables of interest for T-tests
cont.variables <- c("BATHRM", "HF_BATHRM", "ROOMS", "BEDRM", "AYB", "YR_RMDL", "EYB", "STORIES", "GBA",
"KITCHENS", "FIREPLACES")
#Identify categorical variables of interest for chi-square tests
cat.variables <- c("HEAT","AC", "GRADE", "EXTWALL", "ROOF", "INTWALL", "QUADRANT")
#Create a loop that conducts a t-test for each of the above variables
t.test.results <-  lapply(seq(1:length(cont.variables)),function(i){
x <- df.clean[,cont.variables[i]]
y <- df.dropped[,cont.variables[i]]
t.test(x,y, alternative = "two.sided", na.action = na.omit)
})
#Create a loop that reports the significance of each pairwise t-test
for (i in 1:length(cont.variables)){
print(
paste ( "On average, non-missing values have ", signif (100 * t.test.results[[i]]$estimate[[1]] /
t.test.results[[i]]$estimate[[2]], digits = 3 ),"% ", cont.variables[i], " with a t-stat of ",
t.test.results[[i]]$statistic, sep = ""
))
}
#Create a loop that conducts chi-square for each of the categorical variables
df.cat <- df %>% filter( sale.year > 2015)
df.cat$missing <- 0; df.cat[is.na(df.cat$PRICE),"missing"] = 1; df.cat$missing <- as.factor(df.cat$missing)
df.cat <- df.cat %>%  select(cat.variables, missing)
df.cat <-  gather(df.cat, variable, id, 1:7)
df.cat <- df.cat %>% group_by(missing, id) %>% summarize(value = n())
df.cat <-  spread(df.cat, missing, value); colnames(df.cat) <- c( "feature","non-missing", "missing");
df.cat <- df.cat[-(1:2),]
?chisq.test()
df.cat <- df %>% filter( sale.year > 2015)
df.cat$missing <- 0; df.cat[is.na(df.cat$PRICE),"missing"] = 1; df.cat$missing <- as.factor(df.cat$missing)
df.cat <- df.cat %>%  select(cat.variables, missing)
View(df.cat)
View(df.cat)
?chisq.test(df.cat$missing, df.cat$AC)
chisq.test(df.cat$missing, df.cat$AC)
table(df.cat$missing, df.cat$AC)
tab <- table(df.cat$missing, df.cat$AC)
chisq.test(tab)
chisq.test(df$AC, df$missing)
tab <- data.frame(df.cat$missing, df.cat$AC)
chisq.test(tab$df.cat.AC, tab$df.catmissing)
chisq.test(tab$df.cat.AC, tab$df.cat.missing)
tab <- data.frame(df.cat$missing, df.cat$AC)
chisq.test(tab$df.cat.AC, tab$df.cat.missing)
summary ( chisq.test(tab$df.cat.AC, tab$df.cat.missing))
poop <-  ( chisq.test(tab$df.cat.AC, tab$df.cat.missing))
poop
poop$residuals
chi.test <- chisq.test(df.cat$AC, df.cat$missing)
chi.test
summary ( chi.test )
t.test.results <-  lapply(seq(1:length(cont.variables)),function(i){
y <- df.dropped[,cont.variables[i]]
t.test(x,y, alternative = "two.sided", na.action = na.omit)
}
chi.test <- chisq.test(df.cat$AC, df.cat$missing)
chi.test.results <-  lapply(seq(1:length(cat.variables)),function(i){
x <- df.cat[,cat.variables[i]]
y <- df.cat[,missing]
chisq.test(x,y)
})
chi.test.results <-  lapply(seq(1:length(cat.variables)),function(i){
x <- df.cat[,cat.variables[i]]
y <- df.cat[,"missing"]
chisq.test(x,y)
})
chi.test.results[1]
chi.test.results[2]
View(chi.test.results)
for (i in chi.test.results){
print(i$residuals)
}
#Title: missing_values_analysis.R
#Author: Chris Montgomery
#Last Revised: 2/24/2019
#working_directory: ~DATS6101_DataScience/eda_project
#Input: data/dc_residential_data/DC_properties.csv
#Output:
#Description: This script tests differences in housing characteristics between homes with and without price
#values. Characteristics of interest were determined by conversation with group members and can be found in
#EDA_outline.doc
#Import necessary libraries
library(dplyr); library(ggplot2); library(gplots); library(tidyverse)
#Read in the original source data
df.orig <- df <- read.csv("data/dc_residential_data/DC_properties.csv")
#Convert saledate to date, and add sale year column
df$SALEDATE <- as.Date(df$SALEDATE)
df$sale.year <- lubridate::year(df$SALEDATE)
#Create a dataframe that contains clean housing values that will not be dropped
df.clean <- df %>% filter(!is.na(PRICE),  sale.year > 2015)
#Create a dataframe with dropped values for comparison
df.dropped <- df %>% filter(is.na(PRICE),  sale.year > 2015)
#Identify continuous variables of interest for T-tests
cont.variables <- c("BATHRM", "HF_BATHRM", "ROOMS", "BEDRM", "AYB", "YR_RMDL", "EYB", "STORIES", "GBA",
"KITCHENS", "FIREPLACES")
#Identify categorical variables of interest for chi-square tests
cat.variables <- c("HEAT","AC", "CNDTN", "EXTWALL", "ROOF", "INTWALL", "QUADRANT")
#Create a loop that conducts a t-test for each of the above variables
t.test.results <-  lapply(seq(1:length(cont.variables)),function(i){
x <- df.clean[,cont.variables[i]]
y <- df.dropped[,cont.variables[i]]
t.test(x,y, alternative = "two.sided", na.action = na.omit)
})
#Create a loop that reports the significance of each pairwise t-test
for (i in 1:length(cont.variables)){
print(
paste ( "On average, non-missing values have ", signif (100 * t.test.results[[i]]$estimate[[1]] /
t.test.results[[i]]$estimate[[2]], digits = 3 ),"% ", cont.variables[i], " with a t-stat of ",
t.test.results[[i]]$statistic, sep = ""
))
}
#Create a loop that conducts chi-square for each of the categorical variables
df.cat <- df %>% filter( sale.year > 2015)
df.cat$missing <- 0; df.cat[is.na(df.cat$PRICE),"missing"] = 1; df.cat$missing <- as.factor(df.cat$missing)
df.cat <- df.cat %>%  select(cat.variables, missing)
chi.test.results <-  lapply(seq(1:length(cat.variables)),function(i){
x <- df.cat[,cat.variables[i]]
y <- df.cat[,"missing"]
chisq.test(x,y)
})
for (i in chi.test.results){
print(i$residuals)
}
chi.test.results[7]
chi.test.results[6]
chi.test.results[5]
chi.test.results[4]
chi.test.results[3]
chi.test.results[2]
chi.test.results[1]
for (i in chi.test.results){
print(i$residuals)
}
